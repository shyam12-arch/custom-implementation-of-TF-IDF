{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assigns-3(Tf-idf vectoriser).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CHGfaCDd51I",
        "outputId": "2e1ab631-8324-40c3-b5fe-9cbe71ca06c9"
      },
      "source": [
        "## Task-1:\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "\n",
        "## custom implementation for findout idf values and unique words in the corpus by fit function :\n",
        "\n",
        "def unique_word(data):\n",
        "  unique_words=set()\n",
        "  if isinstance(data, (list,)):\n",
        "    for row in data:\n",
        "      for word in row.split():\n",
        "        if len(word)< 2:\n",
        "          continue\n",
        "        unique_words.add(word)\n",
        "    unique_words=sorted(list(unique_words))\n",
        "    vocab={j:i for i,j in enumerate(unique_words)}\n",
        "    return vocab\n",
        "  else:\n",
        "    print(\"you need to pass list of sentence\")\n",
        "\n",
        "\n",
        "corpus=[\"this is the first document\",\"this document is the second document\", \n",
        "\"and this is the third one\",\"is this the first document\"]\n",
        "\n",
        "vocab=unique_word(corpus)\n",
        "\n",
        "def fit(corpus,vocab):\n",
        "  d = {}\n",
        "  n = len(corpus)\n",
        "  for i in vocab:\n",
        "    c = 0\n",
        "    for j in corpus:\n",
        "      if i in j.split():\n",
        "        c += 1\n",
        "        d[i] = 1 + (math.log((1+n)/(c+1)))\n",
        "  return d\n",
        "\n",
        "fit(corpus,vocab)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1.916290731874155,\n",
              " 'document': 1.2231435513142097,\n",
              " 'first': 1.5108256237659907,\n",
              " 'is': 1.0,\n",
              " 'one': 1.916290731874155,\n",
              " 'second': 1.916290731874155,\n",
              " 'the': 1.0,\n",
              " 'third': 1.916290731874155,\n",
              " 'this': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euwC2Ls6eQ29",
        "outputId": "f635da65-44f7-49b6-a77d-596b3ff1d297"
      },
      "source": [
        "## custom implementation for conversion of text into sparse matrix by transform function(text into matrix into sparse matrix):\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def matrix(data,vocab):\n",
        "  rows=[]\n",
        "  columns=[]\n",
        "  values=[]\n",
        "  if isinstance(data,(list,)):\n",
        "    for idx, row in enumerate(data):\n",
        "      word_freq=dict(Counter(row.split()))\n",
        "      for word,freq in word_freq.items():\n",
        "        if len(word)< 2:\n",
        "          continue\n",
        "        col_index= vocab.get(word, -1)\n",
        "        if col_index != -1:\n",
        "          rows.append(idx)\n",
        "          columns.append(col_index)\n",
        "          values.append(freq)\n",
        "    return csr_matrix((values, (rows,columns)),shape=(len(data),len(vocab)))\n",
        "  else:\n",
        "    print(\"you need to pass list of string\")\n",
        "\n",
        "mat= matrix(corpus,vocab).toarray()\n",
        "\n",
        "def transform(mat):\n",
        "  sparse_matrix=[]\n",
        "  for i in range(len(mat)):\n",
        "    for j in range(len(mat[i])):\n",
        "      if mat[i][j] !=0:\n",
        "        temp=[]\n",
        "        temp.append(i)\n",
        "        temp.append(j)\n",
        "        temp.append(mat[i][j])\n",
        "        sparse_matrix.append(temp)\n",
        "  print(sparse_matrix) \n",
        "\n",
        "transform(mat)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 1], [0, 2, 1], [0, 3, 1], [0, 6, 1], [0, 8, 1], [1, 1, 2], [1, 3, 1], [1, 5, 1], [1, 6, 1], [1, 8, 1], [2, 0, 1], [2, 3, 1], [2, 4, 1], [2, 6, 1], [2, 7, 1], [2, 8, 1], [3, 1, 1], [3, 2, 1], [3, 3, 1], [3, 6, 1], [3, 8, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH0SRXbUeQvZ",
        "outputId": "63611b91-fba1-420e-cafb-cd7619a4d5e5"
      },
      "source": [
        "## comparision between custom implementation and sklearn feature names and idf values :\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "skl_output = vectorizer.transform(corpus)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print('')\n",
        "print(vectorizer.idf_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "\n",
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYGzetrKeQOr",
        "outputId": "90850ce3-eaba-4c96-9687-7c525e0b534b"
      },
      "source": [
        "## custom implementation for findout sparse matrix of tf-idf values along with 1st line of corpus :\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def idf(corpus,word):\n",
        "  c = 0\n",
        "  for i in corpus:\n",
        "    if word in i.split():\n",
        "      c += 1\n",
        "  return c    \n",
        "\n",
        "\n",
        "def tf_idf(corpus,vocab):\n",
        "  rows=[]\n",
        "  columns=[]\n",
        "  values=[]\n",
        "  \n",
        "  for idx, row in enumerate(corpus):\n",
        "    word_freq=dict(Counter(row.split()))\n",
        "    for word,freq in word_freq.items():\n",
        "      if len(word)< 2:\n",
        "        continue\n",
        "      col_index= vocab.get(word, -1)\n",
        "      if col_index != -1:\n",
        "        rows.append(idx)\n",
        "        columns.append(col_index)\n",
        "        tf = freq/float(len(row))\n",
        "\n",
        "        idf_ = 1 + math.log((1+len(corpus))/float(1+idf(corpus,word)))\n",
        "\n",
        "        values.append((tf)*(idf_))\n",
        "        \n",
        "  return normalize(csr_matrix((values,(rows,columns)),shape=(len(corpus),len(vocab))))\n",
        "\n",
        "skl_output1 = tf_idf(corpus,vocab) \n",
        "print(skl_output1[0]) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YCrGv2PgKts",
        "outputId": "178e700b-5477-4159-af70-93e67233e3f5"
      },
      "source": [
        "## custom implementation for findout sklearn output :\n",
        "\n",
        "skl_output1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvqheCFj4ls4",
        "outputId": "72a02fd5-eb22-44ef-ede4-697c836285f5"
      },
      "source": [
        "## comparision between custom implementation and sklearn tf-idf values :\n",
        "\n",
        "print(skl_output[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHOdXRlzgL7M",
        "outputId": "d8d5d9fc-818b-427c-92bf-61324db0503d"
      },
      "source": [
        "## comparision between custom implementation and sklearn output :\n",
        "\n",
        "skl_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC7GDTFk4le-",
        "outputId": "d33d17ae-2e14-4da4-c460-63884f696395"
      },
      "source": [
        "## custom implementation for findout tf-idf values for first line of corpus :\n",
        "\n",
        "print(skl_output1[0].toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e96QGVd04lPt",
        "outputId": "a102013e-7adc-490c-934e-415833efaedf"
      },
      "source": [
        "## comparision between custom implementation and sklearn tf-idf values for first line of corpus :\n",
        "\n",
        "print(skl_output[0].toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU2ohT7y4k6U"
      },
      "source": [
        "## Task-2 :"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnn557Vwl4iW"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/cleaned_strings','rb') as f:\n",
        "  corpus_2= pickle.load(f)  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SERcAObwk5lj",
        "outputId": "b791b028-575d-4e1e-939a-0fad2cb839fb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "\n",
        "## custom implementation for findout idf values and unique words in the corpus by fit function :\n",
        "\n",
        "\n",
        "def unique_word(data):\n",
        "  unique_words=set()\n",
        "  if isinstance(data, (list,)):\n",
        "    for row in data:\n",
        "      for word in row.split():\n",
        "        if len(word)< 2:\n",
        "          continue\n",
        "        unique_words.add(word)\n",
        "    unique_words=sorted(list(unique_words))\n",
        "    unique=unique_words[0:50]\n",
        "    vocab={j:i for i,j in enumerate(unique)}\n",
        "    return vocab\n",
        "  else:\n",
        "    print(\"you need to pass list of sentence\")\n",
        "\n",
        "vocab_2 = unique_word(corpus_2)\n",
        "\n",
        "def fit(corpus,vocab):\n",
        "  d = {}\n",
        "  n = len(corpus)\n",
        "  for i in vocab:\n",
        "    c = 0\n",
        "    for j in corpus:\n",
        "      if i in j.split():\n",
        "        c += 1\n",
        "        d[i] = 1 + (math.log((1+n)/(c+1)))\n",
        "  return d\n",
        "\n",
        "k = fit(corpus_2,vocab_2) \n",
        "print(k)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aailiyah': 6.922918004572872, 'abandoned': 6.922918004572872, 'ability': 6.229770824012927, 'abroad': 6.922918004572872, 'absolutely': 5.3134800921387715, 'abstruse': 6.922918004572872, 'abysmal': 6.517452896464707, 'academy': 6.922918004572872, 'accents': 6.922918004572872, 'accessible': 6.922918004572872, 'acclaimed': 6.922918004572872, 'accolades': 6.922918004572872, 'accurate': 6.922918004572872, 'accurately': 6.922918004572872, 'accused': 6.517452896464707, 'achievement': 6.517452896464707, 'achille': 6.922918004572872, 'ackerman': 6.922918004572872, 'act': 6.517452896464707, 'acted': 6.229770824012927, 'acting': 3.9784790254064317, 'action': 5.536623643452981, 'actions': 6.922918004572872, 'actor': 5.3134800921387715, 'actors': 4.671626205966376, 'actress': 6.229770824012927, 'actresses': 6.229770824012927, 'actually': 5.218169912334447, 'adams': 6.922918004572872, 'adaptation': 6.517452896464707, 'add': 6.922918004572872, 'added': 6.922918004572872, 'addition': 6.229770824012927, 'admins': 6.922918004572872, 'admiration': 6.922918004572872, 'admitted': 6.922918004572872, 'adorable': 6.006627272698717, 'adrift': 6.922918004572872, 'adventure': 6.922918004572872, 'advise': 6.517452896464707, 'aerial': 6.229770824012927, 'aesthetically': 6.922918004572872, 'affected': 6.922918004572872, 'affleck': 6.922918004572872, 'afraid': 6.517452896464707, 'africa': 6.517452896464707, 'afternoon': 6.922918004572872, 'age': 6.006627272698717, 'aged': 6.922918004572872, 'ages': 6.922918004572872}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwK-dKGgk5TC",
        "outputId": "fa0cff62-2175-4619-c7c3-4d93343d897e"
      },
      "source": [
        "## comparision between custom implementation and sklearn idf values :\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(corpus_2)\n",
        "skl_output = vectorizer.transform(corpus_2)\n",
        "print(vectorizer.idf_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.922918   6.922918   6.22977082 ... 6.922918   6.5174529  6.922918  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFF1AC3Z-Y4E",
        "outputId": "172ddc5b-161d-40ab-c4ea-c9d99fb1ad1b"
      },
      "source": [
        "## custom implementation for conversion of text into sparse matrix by transform function(text into matrix into sparse matrix):\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def matrix(data,vocab):\n",
        "  rows=[]\n",
        "  columns=[]\n",
        "  values=[]\n",
        "  if isinstance(data,(list,)):\n",
        "    for idx, row in enumerate(data):\n",
        "      word_freq=dict(Counter(row.split()))\n",
        "      for word,freq in word_freq.items():\n",
        "        if len(word)< 2:\n",
        "          continue\n",
        "        col_index= vocab.get(word, -1)\n",
        "        if col_index != -1:\n",
        "          rows.append(idx)\n",
        "          columns.append(col_index)\n",
        "          values.append(freq)\n",
        "    return csr_matrix((values, (rows,columns)),shape=(len(data),len(vocab)))\n",
        "  else:\n",
        "    print(\"you need to pass list of string\")\n",
        "\n",
        "mat= matrix(corpus_2,vocab_2).toarray()\n",
        "\n",
        "def transform(mat):\n",
        "  sparse_matrix=[]\n",
        "  for i in range(len(mat)):\n",
        "    for j in range(len(mat[i])):\n",
        "      if mat[i][j] !=0:\n",
        "        temp=[]\n",
        "        temp.append(i)\n",
        "        temp.append(j)\n",
        "        temp.append(mat[i][j])\n",
        "        sparse_matrix.append(temp)\n",
        "  print(sparse_matrix) \n",
        "\n",
        "transform(mat)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 20, 1], [10, 36, 1], [15, 20, 1], [17, 20, 1], [19, 4, 1], [19, 23, 1], [19, 24, 1], [19, 27, 1], [19, 32, 1], [26, 19, 1], [28, 27, 1], [36, 24, 1], [41, 20, 1], [49, 20, 1], [56, 14, 1], [60, 44, 1], [62, 39, 1], [65, 23, 1], [68, 43, 1], [72, 24, 1], [86, 20, 1], [104, 24, 1], [134, 4, 1], [134, 24, 1], [134, 47, 1], [135, 5, 1], [135, 13, 1], [135, 19, 1], [135, 20, 4], [135, 21, 1], [135, 24, 2], [135, 25, 1], [135, 32, 1], [135, 34, 1], [135, 37, 1], [135, 40, 1], [146, 27, 1], [155, 24, 1], [155, 26, 1], [159, 4, 1], [160, 4, 1], [162, 21, 1], [163, 20, 1], [169, 4, 1], [176, 20, 1], [181, 22, 1], [189, 47, 1], [192, 38, 1], [193, 42, 1], [216, 3, 1], [222, 36, 1], [223, 36, 1], [225, 35, 1], [226, 20, 1], [227, 33, 1], [229, 20, 1], [238, 20, 1], [246, 20, 1], [253, 4, 1], [253, 20, 1], [261, 20, 1], [266, 20, 1], [269, 23, 1], [270, 1, 1], [277, 24, 1], [280, 20, 1], [281, 20, 1], [285, 24, 1], [290, 46, 1], [319, 24, 1], [333, 48, 1], [334, 30, 1], [344, 27, 1], [345, 36, 1], [348, 11, 1], [355, 24, 1], [358, 20, 1], [370, 27, 1], [382, 20, 1], [382, 21, 1], [409, 4, 1], [409, 6, 1], [409, 8, 1], [421, 40, 1], [429, 23, 1], [430, 20, 1], [431, 23, 2], [432, 27, 1], [448, 20, 1], [449, 45, 1], [450, 45, 1], [452, 20, 1], [453, 44, 1], [455, 24, 1], [461, 7, 1], [461, 29, 1], [467, 26, 1], [473, 27, 1], [480, 40, 1], [490, 27, 1], [493, 9, 1], [494, 39, 1], [501, 21, 1], [503, 25, 1], [508, 24, 1], [511, 24, 1], [523, 15, 1], [538, 21, 1], [542, 20, 1], [544, 23, 1], [548, 0, 1], [552, 20, 1], [557, 32, 1], [561, 20, 1], [572, 24, 1], [574, 20, 1], [595, 2, 1], [599, 20, 1], [603, 20, 1], [608, 28, 1], [612, 16, 1], [618, 20, 1], [619, 24, 1], [626, 20, 1], [628, 14, 1], [628, 23, 1], [632, 10, 1], [632, 29, 1], [636, 47, 1], [638, 21, 1], [639, 21, 1], [644, 2, 1], [644, 4, 1], [644, 6, 1], [644, 15, 1], [644, 17, 1], [644, 18, 1], [644, 20, 4], [644, 23, 1], [644, 24, 1], [644, 49, 1], [649, 20, 1], [658, 20, 1], [660, 4, 1], [667, 41, 1], [669, 20, 1], [673, 23, 1], [688, 27, 1], [697, 12, 1], [706, 2, 1], [706, 20, 1], [707, 24, 1], [710, 47, 1], [712, 27, 1], [718, 18, 1], [722, 20, 1], [722, 31, 1], [725, 19, 1], [726, 26, 1], [738, 25, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaBUme0IoTRK",
        "outputId": "4d758295-6970-44e9-b9b5-ae61f6fbefa0"
      },
      "source": [
        "## custom implementation for findout sparse matrix of tf-idf values along with 1st line of corpus_2 :\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def idf(corpus_2,word):\n",
        "  c = 0\n",
        "  for i in corpus:\n",
        "    if word in i.split():\n",
        "      c += 1\n",
        "  return c    \n",
        "\n",
        "\n",
        "def tf_idf(corpus_2,vocab_2):\n",
        "  rows=[]\n",
        "  columns=[]\n",
        "  values=[]\n",
        "  \n",
        "  for idx, row in enumerate(corpus_2):\n",
        "    word_freq=dict(Counter(row.split()))\n",
        "    for word,freq in word_freq.items():\n",
        "      if len(word)< 2:\n",
        "        continue\n",
        "      col_index= vocab_2.get(word, -1)\n",
        "      if col_index != -1:\n",
        "        rows.append(idx)\n",
        "        columns.append(col_index)\n",
        "        tf = freq/float(len(row))\n",
        "\n",
        "        idf_ = 1 + math.log((1+len(corpus_2))/float(1+idf(corpus_2,word)))\n",
        "\n",
        "        values.append((tf)*(idf_))\n",
        "        \n",
        "  return normalize(csr_matrix((values,(rows,columns)),shape=(len(corpus_2),len(vocab_2))))\n",
        "\n",
        "skl_output2 = tf_idf(corpus_2,vocab_2) \n",
        "print(skl_output2[0]) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sJPw1AwrPen",
        "outputId": "a3ebf687-aa86-403c-ca05-2bdbcb056f15"
      },
      "source": [
        "## comparision between custom implementation and sklearn tf-idf values :\n",
        "\n",
        "## In above custom implementation tf-idf values output comes zero bcoz we consider only 50 columns\n",
        "\n",
        "print(skl_output[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2878)\t0.35781145622317734\n",
            "  (0, 2287)\t0.3377679916467555\n",
            "  (0, 1653)\t0.35781145622317734\n",
            "  (0, 1651)\t0.16192317905848022\n",
            "  (0, 1545)\t0.30566026894803877\n",
            "  (0, 720)\t0.4123943870778812\n",
            "  (0, 688)\t0.4123943870778812\n",
            "  (0, 53)\t0.4123943870778812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUMIOT3ns42U",
        "outputId": "a9324393-ca0c-4b72-a735-1b54b4ca5e4b"
      },
      "source": [
        "## custom implementation for findout sklearn output :\n",
        "\n",
        "skl_output2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(746, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FraFvLDxoTHv",
        "outputId": "f3c07c16-49d4-4f08-bb70-261d3e745b5c"
      },
      "source": [
        "## comparision between custom implementation and sklearn output :\n",
        "\n",
        "## In above custom implementation  output comes 50 columns bcoz we consider only 50 columns\n",
        "\n",
        "\n",
        "skl_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(746, 2886)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K--b2vKLqSJe",
        "outputId": "3f6fb7a2-c29e-409a-8736-f27f708dac76"
      },
      "source": [
        "## custom implementation for findout tf-idf values for first line of corpus :\n",
        "\n",
        "print(skl_output2[0].toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS8fEUODqSDf",
        "outputId": "3d92c6ec-3668-4e02-aebc-5b79c5acca4f"
      },
      "source": [
        "## comparision between custom implementation and sklearn tf-idf values for first line of corpus :\n",
        "\n",
        "print(skl_output[0].toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}